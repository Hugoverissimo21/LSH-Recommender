{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "505c3a2c",
   "metadata": {},
   "source": [
    "Use CV Validation to get the best hyperparameters for the LSH model:\n",
    "\n",
    "- `bucketLength` $\\in [0.5, 2.0]$ based on some small research \n",
    "\n",
    "- `numHashTables` $\\in [1, 10]$ so the number of hash tables is not too large\n",
    "\n",
    "- `approxSimilarityJoin` threshold $\\in [0, 1.41]$ so the cosine similarity is between 0 and 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667f6733",
   "metadata": {},
   "source": [
    "the idea will be to create a json for keeping tracke of the parameters and like to like 10-folds but do a partial cross validation using only 5 until we get an idea of the best parameters and then 10-fold cv to get the final model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51538ba4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6b63a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import collect_list, struct\n",
    "from pyspark.ml.linalg import Vectors, SparseVector\n",
    "from pyspark.sql import Row\n",
    "from pyspark.ml.feature import Normalizer\n",
    "from pyspark.ml.feature import BucketedRandomProjectionLSH\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import sum as sql_sum, col\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b310d97c",
   "metadata": {},
   "source": [
    "# Treat the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa43846",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ItemItemCF\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "data = spark.read.csv(\"data/100k.csv\", header=True, inferSchema=True) \\\n",
    "            .select(\"userId\", \"movieId\", \"rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36d2fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 10 folds of data\n",
    "folds = data.randomSplit([0.1]*10, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7888433a",
   "metadata": {},
   "source": [
    "# Create functions automate the CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2e496d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def item_item_cf_similarities(ratings):\n",
    "    # get the number of unique users\n",
    "    num_users = ratings.select(\"userId\").distinct().count()\n",
    "\n",
    "    # create the sparse vector for movie function\n",
    "    def to_sparse_vector(user_ratings, size):\n",
    "        # Sort by userId to get strictly increasing indices\n",
    "        sorted_pairs = sorted(user_ratings, key=lambda x: x.userId)\n",
    "        indices = [x.userId - 1 for x in sorted_pairs]\n",
    "        values = [x.rating for x in sorted_pairs]\n",
    "        return Vectors.sparse(size, indices, values)\n",
    "\n",
    "    # group by movieId and collect user ratings\n",
    "    item_user = ratings.groupBy(\"movieId\") \\\n",
    "        .agg(collect_list(struct(\"userId\", \"rating\")).alias(\"user_ratings\"))\n",
    "\n",
    "    # convert that to a sparse vector\n",
    "    item_vector_rdd = item_user.rdd.map(\n",
    "        lambda row: Row(\n",
    "            movieId=row[\"movieId\"],\n",
    "            features=to_sparse_vector(row[\"user_ratings\"], num_users)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # convert to DataFrame because of Normalizer (MLlib)\n",
    "    item_vectors = spark.createDataFrame(item_vector_rdd)\n",
    "\n",
    "    # normalizing with L2 (Euclidean) norm (p=2)\n",
    "    normalizer = Normalizer(inputCol=\"features\", outputCol=\"norm_features\", p=2.0)\n",
    "    normalized = normalizer.transform(item_vectors)\n",
    "\n",
    "    # create the LSH model\n",
    "    lsh = BucketedRandomProjectionLSH(\n",
    "        inputCol=\"norm_features\",\n",
    "        outputCol=\"hashes\",\n",
    "        bucketLength=1.5,\n",
    "        numHashTables=3\n",
    "    )\n",
    "\n",
    "    # fit the model\n",
    "    lsh_model = lsh.fit(normalized)\n",
    "\n",
    "    # get the approximate neighbors\n",
    "    neighbors = lsh_model.approxSimilarityJoin(\n",
    "        normalized,\n",
    "        normalized,\n",
    "        threshold=1.0, # distance threshold\n",
    "        distCol=\"distance\"\n",
    "    ).filter(col(\"datasetA.movieId\") < col(\"datasetB.movieId\"))  # avoid bottom triangle (reverse + self)\n",
    "\n",
    "    # convert the distance to cosine similarity\n",
    "    neighbors_cosine = neighbors.withColumn(\n",
    "        \"cosine_sim\",\n",
    "        1 - (col(\"distance\") ** 2) / 2\n",
    "    ).select(\n",
    "        col(\"datasetA.movieId\").alias(\"movie_i\"),\n",
    "        col(\"datasetB.movieId\").alias(\"movie_j\"),\n",
    "        \"cosine_sim\"\n",
    "    )\n",
    "\n",
    "    # add reverse pairs: (i,j) -> (i,j) and (j,i)\n",
    "    reverse = neighbors_cosine.selectExpr(\"movie_j as movie_i\", \"movie_i as movie_j\", \"cosine_sim\")\n",
    "    similarities = neighbors_cosine.union(reverse)\n",
    "\n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90fa8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def item_item_cf_predictions(ratings, similarities, test):\n",
    "    # get the neighbors of the target movies\n",
    "    test_with_ratings = test.alias(\"t\") \\\n",
    "        .join(similarities.alias(\"s\"), col(\"t.movieId\") == col(\"s.movie_i\")) \\\n",
    "        .join(ratings.alias(\"r\"), (col(\"t.userId\") == col(\"r.userId\")) & (col(\"s.movie_j\") == col(\"r.movieId\"))) \\\n",
    "        .select(\n",
    "            col(\"t.userId\"),\n",
    "            col(\"t.movieId\").alias(\"target_movie\"),\n",
    "            col(\"s.movie_j\").alias(\"neighbor_movie\"),\n",
    "            col(\"s.cosine_sim\"),\n",
    "            col(\"r.rating\").alias(\"neighbor_rating\")\n",
    "        )\n",
    "\n",
    "    # get the predicted rating\n",
    "    predictions = test_with_ratings.groupBy(\"userId\", \"target_movie\").agg(\n",
    "        (sql_sum(col(\"cosine_sim\") * col(\"neighbor_rating\")) / sql_sum(col(\"cosine_sim\"))).alias(\"pred_rating\")\n",
    "    )\n",
    "\n",
    "    final = predictions.alias(\"p\").join(\n",
    "        test.alias(\"t\"),\n",
    "        (col(\"p.userId\") == col(\"t.userId\")) & (col(\"p.target_movie\") == col(\"t.movieId\"))\n",
    "    ).select(\n",
    "        col(\"t.userId\"),\n",
    "        col(\"t.movieId\"),\n",
    "        col(\"p.pred_rating\"),\n",
    "        col(\"t.rating\").alias(\"actual_rating\")\n",
    "    )\n",
    "\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6ea656",
   "metadata": {},
   "outputs": [],
   "source": [
    "def item_item_cf_results(final):\n",
    "    # RMSE\n",
    "    evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"actual_rating\", predictionCol=\"pred_rating\")\n",
    "    rmse = evaluator.evaluate(final)\n",
    "\n",
    "    # MAE\n",
    "    mae_evaluator = RegressionEvaluator(metricName=\"mae\", labelCol=\"actual_rating\", predictionCol=\"pred_rating\")\n",
    "    mae = mae_evaluator.evaluate(final)\n",
    "\n",
    "    return rmse, mae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5f0e31",
   "metadata": {},
   "source": [
    "# CV Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8fb3e4",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MDLE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
